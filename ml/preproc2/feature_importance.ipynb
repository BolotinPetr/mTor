{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результыты. \n",
    "\n",
    "1) Качество на cross-validation порядка 90-95 в зависимости от регуляризации. \n",
    "\n",
    "2) Гены из пути mTor регулярно попадают в важные признаки при разной регуляризации, разных моделях и разных разбиениях cv. \n",
    "\n",
    "3) Если использозовать для предсказания плюрипотентности только гены mTor, то f1 = 69, accuracy = 0.78, precision = 0.73, recall=75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Препроцессинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_table2.csv').T\n",
    "\n",
    "Gen_ID = df[95:96]\n",
    "df = df.drop(df.index[95])\n",
    "\n",
    "target = []\n",
    "for index in df.index:\n",
    "    res_ev = re.search('_EV_', index)\n",
    "    res_oskm = re.search('_OSKM_', index)\n",
    "    if re.search('_EV_', index) != None:\n",
    "        target.append(1)\n",
    "    if re.search('_OSKM_', index) != None:\n",
    "        target.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>62151</th>\n",
       "      <th>62152</th>\n",
       "      <th>62153</th>\n",
       "      <th>62154</th>\n",
       "      <th>62155</th>\n",
       "      <th>62156</th>\n",
       "      <th>62157</th>\n",
       "      <th>62158</th>\n",
       "      <th>62159</th>\n",
       "      <th>62160</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gen_ID</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENSG00000227232</td>\n",
       "      <td>ENSG00000243485</td>\n",
       "      <td>ENSG00000221311</td>\n",
       "      <td>ENSG00000237613</td>\n",
       "      <td>ENSG00000268020</td>\n",
       "      <td>ENSG00000240361</td>\n",
       "      <td>ENSG00000186092</td>\n",
       "      <td>ENSG00000238009</td>\n",
       "      <td>ENSG00000239945</td>\n",
       "      <td>...</td>\n",
       "      <td>ERCC-00157</td>\n",
       "      <td>ERCC-00158</td>\n",
       "      <td>ERCC-00160</td>\n",
       "      <td>ERCC-00162</td>\n",
       "      <td>ERCC-00163</td>\n",
       "      <td>ERCC-00164</td>\n",
       "      <td>ERCC-00165</td>\n",
       "      <td>ERCC-00168</td>\n",
       "      <td>ERCC-00170</td>\n",
       "      <td>ERCC-00171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0                1                2                3      \\\n",
       "Gen_ID  ENSG00000223972  ENSG00000227232  ENSG00000243485  ENSG00000221311   \n",
       "\n",
       "                  4                5                6                7      \\\n",
       "Gen_ID  ENSG00000237613  ENSG00000268020  ENSG00000240361  ENSG00000186092   \n",
       "\n",
       "                  8                9         ...           62151       62152  \\\n",
       "Gen_ID  ENSG00000238009  ENSG00000239945     ...      ERCC-00157  ERCC-00158   \n",
       "\n",
       "             62153       62154       62155       62156       62157  \\\n",
       "Gen_ID  ERCC-00160  ERCC-00162  ERCC-00163  ERCC-00164  ERCC-00165   \n",
       "\n",
       "             62158       62159       62160  \n",
       "Gen_ID  ERCC-00168  ERCC-00170  ERCC-00171  \n",
       "\n",
       "[1 rows x 62161 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gen_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_pipe = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', C=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_pipe.fit(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85716135716135733"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit_pipe, df, target, cv=6, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(1, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = GridSearchCV(logit_pipe, dict(logisticregression__C=Cs), verbose=1, error_score='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='f1',\n",
       "       estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__C': array([   10.     ,    16.68101,    27.82559,    46.41589,    77.42637,\n",
       "         129.15497,   215.44347,   359.38137,   599.48425,  1000.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   29.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='f1',\n",
       "       estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__C': array([   10.     ,    16.68101,    27.82559,    46.41589,    77.42637,\n",
       "         129.15497,   215.44347,   359.38137,   599.48425,  1000.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.61410133,  0.61544251,  0.65012574,  0.6397864 ,  0.62910628,\n",
       "         0.72851038,  0.65046597,  0.71618183,  0.69415808,  0.70983601]),\n",
       " 'mean_score_time': array([ 0.09073162,  0.09105857,  0.10306787,  0.09540184,  0.09440136,\n",
       "         0.10240658,  0.09773151,  0.10707331,  0.09606854,  0.10474094]),\n",
       " 'mean_test_score': array([ 0.92708333,  0.91666667,  0.89583333,  0.90625   ,  0.92708333,\n",
       "         0.91666667,  0.90625   ,  0.9375    ,  0.92708333,  0.875     ]),\n",
       " 'mean_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'param_logisticregression__C': masked_array(data = [10.0 16.681005372000591 27.825594022071243 46.415888336127772\n",
       "  77.426368268112697 129.15496650148839 215.44346900318823\n",
       "  359.38136638046257 599.48425031894089 1000.0],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'logisticregression__C': 10.0},\n",
       "  {'logisticregression__C': 16.681005372000591},\n",
       "  {'logisticregression__C': 27.825594022071243},\n",
       "  {'logisticregression__C': 46.415888336127772},\n",
       "  {'logisticregression__C': 77.426368268112697},\n",
       "  {'logisticregression__C': 129.15496650148839},\n",
       "  {'logisticregression__C': 215.44346900318823},\n",
       "  {'logisticregression__C': 359.38136638046257},\n",
       "  {'logisticregression__C': 599.48425031894089},\n",
       "  {'logisticregression__C': 1000.0}),\n",
       " 'rank_test_score': array([ 2,  5,  9,  7,  2,  5,  7,  1,  2, 10]),\n",
       " 'split0_test_score': array([ 0.96969697,  1.        ,  0.93939394,  0.93939394,  0.96969697,\n",
       "         0.96969697,  0.93939394,  0.96969697,  1.        ,  0.90909091]),\n",
       " 'split0_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split1_test_score': array([ 0.96875,  0.96875,  0.9375 ,  0.9375 ,  0.9375 ,  0.9375 ,\n",
       "         0.9375 ,  0.96875,  0.90625,  0.90625]),\n",
       " 'split1_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split2_test_score': array([ 0.83870968,  0.77419355,  0.80645161,  0.83870968,  0.87096774,\n",
       "         0.83870968,  0.83870968,  0.87096774,  0.87096774,  0.80645161]),\n",
       " 'split2_train_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'std_fit_time': array([ 0.00544037,  0.00941927,  0.01227172,  0.00613482,  0.00823375,\n",
       "         0.07279582,  0.01497682,  0.00946523,  0.02998106,  0.00368554]),\n",
       " 'std_score_time': array([ 0.00286959,  0.00216849,  0.00711593,  0.00531705,  0.00262745,\n",
       "         0.015466  ,  0.00818889,  0.00780532,  0.00374402,  0.01277267]),\n",
       " 'std_test_score': array([ 0.06103175,  0.09922767,  0.06173159,  0.0466496 ,  0.04095417,\n",
       "         0.05544216,  0.0466496 ,  0.04594857,  0.0546735 ,  0.04735368]),\n",
       " 'std_train_score': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97222222222222221"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_best = make_pipeline(LogisticRegression(penalty='l1', C=1000))\n",
    "logit_best.fit(df, target)\n",
    "cross_val_score(logit_best, df, target, cv=6, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24408a79c88>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24408573cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logit_best.steps[0][1].coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mTor = list(pd.read_csv('mTOR_path.txt').columns)\n",
    "mTor = [re.sub(' ', '', x) for x in mTor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_genes(logit_coefs):\n",
    "    best_logit_features = [x for x in logit_coefs if x != 0]\n",
    "    best_logit_features_numbers = [list(logit_coefs).index(x) for x in best_logit_features]\n",
    "    best_genes = [Gen_ID[x][0] for x in best_logit_features_numbers]\n",
    "    return best_logit_features, best_logit_features_numbers, best_genes\n",
    "\n",
    "def compare_with_mtor(best_genes, mtor_genes):\n",
    "    return set(best_genes) & set(mtor_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5573\n"
     ]
    }
   ],
   "source": [
    "b_l, b_log_feachures, b_genes = best_genes(logit_best.steps[0][1].coef_[0])\n",
    "print(len(b_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENSG00000023287',\n",
       " 'ENSG00000063046',\n",
       " 'ENSG00000067560',\n",
       " 'ENSG00000072803',\n",
       " 'ENSG00000075651',\n",
       " 'ENSG00000085721',\n",
       " 'ENSG00000100030',\n",
       " 'ENSG00000105173',\n",
       " 'ENSG00000106615',\n",
       " 'ENSG00000108443',\n",
       " 'ENSG00000108953',\n",
       " 'ENSG00000116954',\n",
       " 'ENSG00000118515',\n",
       " 'ENSG00000119487',\n",
       " 'ENSG00000126934',\n",
       " 'ENSG00000132155',\n",
       " 'ENSG00000134308',\n",
       " 'ENSG00000136238',\n",
       " 'ENSG00000140992',\n",
       " 'ENSG00000150593',\n",
       " 'ENSG00000151247',\n",
       " 'ENSG00000154229',\n",
       " 'ENSG00000155792',\n",
       " 'ENSG00000155876',\n",
       " 'ENSG00000161960',\n",
       " 'ENSG00000164327',\n",
       " 'ENSG00000164924',\n",
       " 'ENSG00000166913',\n",
       " 'ENSG00000167658',\n",
       " 'ENSG00000169032',\n",
       " 'ENSG00000170027',\n",
       " 'ENSG00000172115',\n",
       " 'ENSG00000175224',\n",
       " 'ENSG00000176171',\n",
       " 'ENSG00000187840',\n",
       " 'ENSG00000198793',\n",
       " 'ENSG00000204673',\n",
       " 'ENSG00000213281'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_with_mtor(b_genes, mTor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENSG00000067560',\n",
       " 'ENSG00000108953',\n",
       " 'ENSG00000134308',\n",
       " 'ENSG00000164924',\n",
       " 'ENSG00000170027'}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_with_mtor(b_genes, mTor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENSG00000067560',\n",
       " 'ENSG00000100811',\n",
       " 'ENSG00000128245',\n",
       " 'ENSG00000134308',\n",
       " 'ENSG00000136238',\n",
       " 'ENSG00000151247',\n",
       " 'ENSG00000155876',\n",
       " 'ENSG00000164327',\n",
       " 'ENSG00000164924',\n",
       " 'ENSG00000166913',\n",
       " 'ENSG00000170027',\n",
       " 'ENSG00000172115'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_with_mtor(b_genes, mTor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENSG00000067560',\n",
       " 'ENSG00000100811',\n",
       " 'ENSG00000106615',\n",
       " 'ENSG00000134308',\n",
       " 'ENSG00000136238',\n",
       " 'ENSG00000151247',\n",
       " 'ENSG00000164924',\n",
       " 'ENSG00000166913',\n",
       " 'ENSG00000170027',\n",
       " 'ENSG00000172115'}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_with_mtor(b_genes, mTor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENSG00000067560',\n",
       " 'ENSG00000100811',\n",
       " 'ENSG00000106615',\n",
       " 'ENSG00000132155',\n",
       " 'ENSG00000134308',\n",
       " 'ENSG00000136238',\n",
       " 'ENSG00000164327',\n",
       " 'ENSG00000164924',\n",
       " 'ENSG00000166913',\n",
       " 'ENSG00000170027',\n",
       " 'ENSG00000172115'}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_with_mtor(b_genes, mTor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for_german = np.array([[g, w] for g, w in zip(b_genes, b_l)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('<U18') and format specifier ('%.18e %.18e')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Petr\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1253\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m                     \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not numpy.str_",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-826a413851d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Output1.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfor_german\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Petr\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments)\u001b[0m\n\u001b[0;32m   1256\u001b[0m                     raise TypeError(\"Mismatch between array dtype ('%s') and \"\n\u001b[0;32m   1257\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m                                     % (str(X.dtype), format))\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m             \u001b[0mfooter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfooter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Mismatch between array dtype ('<U18') and format specifier ('%.18e %.18e')"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"Output1.csv\", for_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b_genes) - len(b_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1123"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('Output2.txt', 'w') \n",
    "file.write(str(for_german))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=62161, step=1)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_with_mtor(b_genes, mTor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('new_table2.csv').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtor_cols = []\n",
    "for i in range(len(data.columns)):\n",
    "    if data[i][95] in mTor:\n",
    "        mtor_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train = df[mtor_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_pipe_new = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', C=0.4, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90714285714285714"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit_pipe_new, new_train, target, cv=7, scoring='recall').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 201 candidates, totalling 603 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 603 out of 603 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__C': array([  0.1    ,   0.10233, ...,   9.77237,  10.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs_new = np.logspace(-1, 1, 201)\n",
    "estimator_new = GridSearchCV(logit_pipe, dict(logisticregression__C=Cs_new), verbose=1, scoring='recall')\n",
    "estimator_new.fit(new_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_new.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75274621212121218"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_new.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00333524,  0.00266345,  0.00366815,  0.00300916,  0.00233626,\n",
       "         0.0023276 ,  0.00200796,  0.00200804,  0.00199517,  0.0016679 ,\n",
       "         0.00200224,  0.00266274,  0.00233436,  0.002002  ,  0.00200232,\n",
       "         0.00233642,  0.00233515,  0.00333627,  0.00234199,  0.00200192,\n",
       "         0.00199517,  0.00200256,  0.00200915,  0.00200748,  0.00200192,\n",
       "         0.00200192,  0.0020016 ,  0.00199477,  0.00200152,  0.00200184,\n",
       "         0.00200168,  0.00200137,  0.00200144,  0.0020016 ,  0.00200208,\n",
       "         0.00200129,  0.00200319,  0.00200168,  0.00200081,  0.0020016 ,\n",
       "         0.00200184,  0.00200208,  0.00200137,  0.00200144,  0.00200176,\n",
       "         0.00200121,  0.00200152,  0.00200152,  0.00200144,  0.00200057,\n",
       "         0.00233475,  0.00200232,  0.00200176,  0.00233499,  0.00200256,\n",
       "         0.00200184,  0.00266226,  0.00166845,  0.00234151,  0.00200137,\n",
       "         0.00200137,  0.0020016 ,  0.00200137,  0.00200176,  0.00200192,\n",
       "         0.00233547,  0.00200804,  0.0026559 ,  0.00200121,  0.00200121,\n",
       "         0.00200152,  0.0020074 ,  0.00266902,  0.00233547,  0.00200192,\n",
       "         0.00200176,  0.00233515,  0.00233515,  0.00200176,  0.00200168,\n",
       "         0.00234079,  0.002002  ,  0.00200192,  0.00200248,  0.00233587,\n",
       "         0.00200216,  0.00266902,  0.00200184,  0.00200152,  0.00233483,\n",
       "         0.00233491,  0.00200184,  0.00200192,  0.00233515,  0.00233499,\n",
       "         0.0026691 ,  0.00233563,  0.00266822,  0.00200168,  0.00233507,\n",
       "         0.00233547,  0.00233515,  0.00232951,  0.00233483,  0.00200176,\n",
       "         0.00300217,  0.00233563,  0.00233515,  0.00233523,  0.00233523,\n",
       "         0.00233515,  0.00266838,  0.00266862,  0.00266854,  0.0033354 ,\n",
       "         0.00333325,  0.00233523,  0.00266878,  0.00266814,  0.00233547,\n",
       "         0.00233634,  0.00266854,  0.00266902,  0.00266894,  0.00266814,\n",
       "         0.00266838,  0.00266878,  0.00266878,  0.00300161,  0.00300177,\n",
       "         0.00266854,  0.00266854,  0.00267506,  0.00300217,  0.00299652,\n",
       "         0.00300217,  0.00334231,  0.00334183,  0.00333484,  0.00300852,\n",
       "         0.00301417,  0.00300256,  0.00300113,  0.00333587,  0.00333548,\n",
       "         0.00300376,  0.00333587,  0.00333007,  0.00332959,  0.0033292 ,\n",
       "         0.00333619,  0.00332904,  0.0033416 ,  0.00366934,  0.00367562,\n",
       "         0.00333563,  0.00366855,  0.00333492,  0.0033323 ,  0.00300185,\n",
       "         0.00400233,  0.00366918,  0.0036691 ,  0.00367498,  0.00366942,\n",
       "         0.00366918,  0.00366338,  0.00400297,  0.00466951,  0.0040017 ,\n",
       "         0.00400194,  0.00400178,  0.00400178,  0.00400225,  0.00433064,\n",
       "         0.00400241,  0.00434208,  0.0043366 ,  0.00400273,  0.00400321,\n",
       "         0.00432952,  0.00400201,  0.00433548,  0.0043366 ,  0.00400273,\n",
       "         0.00433024,  0.00433032,  0.0050017 ,  0.00500345,  0.00467563,\n",
       "         0.00733678,  0.00500194,  0.00566379,  0.00566928,  0.00566864,\n",
       "         0.00500202,  0.00600266,  0.00600314,  0.0059998 ,  0.00633772,\n",
       "         0.00633772]),\n",
       " 'mean_score_time': array([ 0.00100128,  0.00100636,  0.00066757,  0.00199509,  0.00099945,\n",
       "         0.0003341 ,  0.0006671 ,  0.00100056,  0.00067353,  0.00100032,\n",
       "         0.00066678,  0.00100104,  0.00100772,  0.00100088,  0.00100001,\n",
       "         0.00133864,  0.00133435,  0.00100096,  0.00100072,  0.00066694,\n",
       "         0.00066733,  0.00066678,  0.00033331,  0.00066725,  0.00100048,\n",
       "         0.00100096,  0.00066686,  0.00100756,  0.00033355,  0.00100056,\n",
       "         0.00066749,  0.0010008 ,  0.00100088,  0.00033371,  0.        ,\n",
       "         0.00100096,  0.00099977,  0.00033355,  0.00100072,  0.00100104,\n",
       "         0.00066717,  0.00100104,  0.0006671 ,  0.00066749,  0.00100088,\n",
       "         0.00100112,  0.00100056,  0.00100056,  0.00100096,  0.00100096,\n",
       "         0.00066725,  0.0010004 ,  0.00100088,  0.0006671 ,  0.00100017,\n",
       "         0.00100088,  0.00033355,  0.00100064,  0.00066717,  0.00100088,\n",
       "         0.00100072,  0.00100104,  0.00100048,  0.00033363,  0.00066805,\n",
       "         0.        ,  0.00066694,  0.00133491,  0.00100096,  0.00100088,\n",
       "         0.00100088,  0.00100088,  0.        ,  0.00033339,  0.00066678,\n",
       "         0.00100088,  0.00066717,  0.        ,  0.00033347,  0.00100668,\n",
       "         0.00066034,  0.00100048,  0.00100017,  0.00099985,  0.00100032,\n",
       "         0.00100032,  0.00033339,  0.00100056,  0.0010008 ,  0.00100088,\n",
       "         0.00066694,  0.00100064,  0.00100056,  0.00100088,  0.00066694,\n",
       "         0.00066702,  0.00099444,  0.00066757,  0.0010004 ,  0.00066686,\n",
       "         0.00066686,  0.00100017,  0.00066694,  0.00100064,  0.00100056,\n",
       "         0.00033355,  0.0010004 ,  0.00100056,  0.0010008 ,  0.00100048,\n",
       "         0.00066678,  0.0006671 ,  0.00033339,  0.00100056,  0.00066741,\n",
       "         0.00100048,  0.0010004 ,  0.00066694,  0.00066678,  0.00066694,\n",
       "         0.00100032,  0.00033331,  0.00066757,  0.00033331,  0.00100072,\n",
       "         0.0006671 ,  0.00066678,  0.00100048,  0.00033355,  0.00066702,\n",
       "         0.00100589,  0.00066694,  0.00100025,  0.00066026,  0.00100112,\n",
       "         0.0006601 ,  0.00100025,  0.00100064,  0.00100136,  0.00132799,\n",
       "         0.00066694,  0.0010012 ,  0.00100136,  0.        ,  0.00100128,\n",
       "         0.00100557,  0.00066702,  0.00100644,  0.00101336,  0.00066678,\n",
       "         0.00067266,  0.00100104,  0.00066773,  0.00066749,  0.        ,\n",
       "         0.00100088,  0.00100271,  0.00100136,  0.00100263,  0.00100064,\n",
       "         0.0010012 ,  0.00066725,  0.00100104,  0.00100088,  0.00033355,\n",
       "         0.00100072,  0.00067321,  0.00066129,  0.00100064,  0.00100136,\n",
       "         0.00100112,  0.00066757,  0.00100168,  0.00066789,  0.00100652,\n",
       "         0.00033355,  0.00066106,  0.00099468,  0.00066098,  0.00100064,\n",
       "         0.00100112,  0.00066797,  0.00066765,  0.00099476,  0.00100104,\n",
       "         0.0010016 ,  0.00134039,  0.0010012 ,  0.00099508,  0.00066694,\n",
       "         0.00133483,  0.00100176,  0.00100128,  0.        ,  0.00100215,\n",
       "         0.00100191,  0.00100176,  0.00100168,  0.00100732,  0.00100088,\n",
       "         0.00066694]),\n",
       " 'mean_test_score': array([ 0.75274621,  0.75274621,  0.75274621,  0.72045455,  0.72045455,\n",
       "         0.72045455,  0.72045455,  0.72045455,  0.72045455,  0.72045455,\n",
       "         0.68920455,  0.68920455,  0.68920455,  0.68920455,  0.68920455,\n",
       "         0.68920455,  0.68920455,  0.68920455,  0.68920455,  0.68920455,\n",
       "         0.68920455,  0.68920455,  0.68920455,  0.68920455,  0.68920455,\n",
       "         0.68920455,  0.68920455,  0.68920455,  0.68920455,  0.68920455,\n",
       "         0.68920455,  0.68920455,  0.68920455,  0.65691288,  0.65691288,\n",
       "         0.65691288,  0.65691288,  0.62566288,  0.62566288,  0.62566288,\n",
       "         0.62566288,  0.62566288,  0.62566288,  0.59337121,  0.59337121,\n",
       "         0.56306818,  0.56306818,  0.56306818,  0.56306818,  0.56306818,\n",
       "         0.56306818,  0.56306818,  0.53077652,  0.53077652,  0.53077652,\n",
       "         0.49952652,  0.49952652,  0.49952652,  0.49952652,  0.49952652,\n",
       "         0.49952652,  0.49952652,  0.49952652,  0.49952652,  0.49952652,\n",
       "         0.53077652,  0.53077652,  0.53077652,  0.53077652,  0.53077652,\n",
       "         0.53077652,  0.56202652,  0.56202652,  0.56202652,  0.56202652,\n",
       "         0.56202652,  0.53172348,  0.53172348,  0.53172348,  0.53172348,\n",
       "         0.53172348,  0.53172348,  0.53172348,  0.53172348,  0.53172348,\n",
       "         0.53172348,  0.53172348,  0.53172348,  0.53172348,  0.53172348,\n",
       "         0.53172348,  0.53172348,  0.53172348,  0.53172348,  0.53172348,\n",
       "         0.53172348,  0.50047348,  0.50047348,  0.50047348,  0.50047348,\n",
       "         0.50047348,  0.53276515,  0.53276515,  0.53276515,  0.53276515,\n",
       "         0.53276515,  0.53276515,  0.53276515,  0.53276515,  0.50047348,\n",
       "         0.50047348,  0.50047348,  0.50047348,  0.50047348,  0.50047348,\n",
       "         0.50047348,  0.50047348,  0.50047348,  0.46922348,  0.46922348,\n",
       "         0.46922348,  0.46922348,  0.53077652,  0.53077652,  0.49848485,\n",
       "         0.49848485,  0.49848485,  0.55909091,  0.55909091,  0.55909091,\n",
       "         0.55909091,  0.55909091,  0.55909091,  0.55909091,  0.59138258,\n",
       "         0.59138258,  0.59138258,  0.59138258,  0.59138258,  0.59138258,\n",
       "         0.59138258,  0.59138258,  0.62263258,  0.62263258,  0.62263258,\n",
       "         0.62263258,  0.62263258,  0.62263258,  0.62263258,  0.62263258,\n",
       "         0.62263258,  0.62263258,  0.62263258,  0.62263258,  0.65293561,\n",
       "         0.65293561,  0.65293561,  0.65293561,  0.65293561,  0.65293561,\n",
       "         0.65293561,  0.65293561,  0.65293561,  0.65293561,  0.65293561,\n",
       "         0.65293561,  0.65293561,  0.65293561,  0.65293561,  0.65293561,\n",
       "         0.65293561,  0.65293561,  0.65293561,  0.65293561,  0.65293561,\n",
       "         0.59043561,  0.59043561,  0.59043561,  0.59043561,  0.59043561,\n",
       "         0.59043561,  0.59043561,  0.59043561,  0.59043561,  0.59043561,\n",
       "         0.59043561,  0.59043561,  0.59043561,  0.59043561,  0.59043561,\n",
       "         0.59043561,  0.59043561,  0.59043561,  0.62073864,  0.62073864,\n",
       "         0.65104167,  0.65104167,  0.65104167,  0.65104167,  0.65104167,\n",
       "         0.65104167]),\n",
       " 'mean_train_score': array([ 0.89105339,  0.87590188,  0.87590188,  0.87590188,  0.87590188,\n",
       "         0.87590188,  0.86075036,  0.86075036,  0.84559885,  0.87590188,\n",
       "         0.87590188,  0.87590188,  0.89105339,  0.89105339,  0.86002886,\n",
       "         0.87518038,  0.87518038,  0.85930736,  0.85930736,  0.84415584,\n",
       "         0.84415584,  0.82900433,  0.82900433,  0.82900433,  0.82900433,\n",
       "         0.82900433,  0.82900433,  0.82900433,  0.82900433,  0.82900433,\n",
       "         0.85930736,  0.85930736,  0.85930736,  0.85930736,  0.85930736,\n",
       "         0.85930736,  0.85930736,  0.89033189,  0.89033189,  0.89033189,\n",
       "         0.89033189,  0.89033189,  0.89033189,  0.90620491,  0.90620491,\n",
       "         0.89033189,  0.89033189,  0.89033189,  0.89033189,  0.89033189,\n",
       "         0.89033189,  0.89033189,  0.89033189,  0.89033189,  0.89033189,\n",
       "         0.89033189,  0.89033189,  0.90620491,  0.90620491,  0.89105339,\n",
       "         0.89105339,  0.89105339,  0.90620491,  0.90620491,  0.92207792,\n",
       "         0.92207792,  0.92207792,  0.92207792,  0.92207792,  0.92207792,\n",
       "         0.92207792,  0.93795094,  0.93795094,  0.93795094,  0.93795094,\n",
       "         0.93795094,  0.95382395,  0.95382395,  0.95382395,  0.95382395,\n",
       "         0.95382395,  0.95382395,  0.95382395,  0.95382395,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.96969697,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.96969697,  0.96969697,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.96969697,  0.96969697,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.96969697,  0.96969697,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.96969697,  0.96969697,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.96969697,  0.96969697,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.96969697,  0.96969697,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.96969697,  0.96969697,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.96969697,  0.96969697,  0.96969697,\n",
       "         0.96969697,  0.96969697,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848,  0.98484848,  0.98484848,  0.98484848,  0.98484848,\n",
       "         0.98484848]),\n",
       " 'param_logisticregression__C': masked_array(data = [0.10000000000000001 0.10232929922807542 0.10471285480508996\n",
       "  0.10715193052376065 0.10964781961431851 0.11220184543019636\n",
       "  0.11481536214968829 0.11748975549395298 0.12022644346174127\n",
       "  0.12302687708123815 0.12589254117941673 0.12882495516931339\n",
       "  0.1318256738556407 0.13489628825916536 0.13803842646028849\n",
       "  0.14125375446227545 0.14454397707459277 0.14791083881682077\n",
       "  0.15135612484362079 0.15488166189124811 0.15848931924611134\n",
       "  0.16218100973589297 0.16595869074375605 0.16982436524617442\n",
       "  0.17378008287493754 0.17782794100389229 0.18197008586099836\n",
       "  0.18620871366628675 0.19054607179632474 0.19498445997580455\n",
       "  0.19952623149688797 0.20417379446695297 0.20892961308540398\n",
       "  0.21379620895022325 0.21877616239495529 0.223872113856834\n",
       "  0.22908676527677729 0.2344228815319922 0.23988329190194904\n",
       "  0.24547089156850305 0.25118864315095801 0.25703957827688639\n",
       "  0.26302679918953814 0.26915348039269155 0.27542287033381663\n",
       "  0.28183829312644537 0.28840315031266056 0.29512092266663853\n",
       "  0.3019951720402016 0.30902954325135906 0.31622776601683794\n",
       "  0.32359365692962827 0.33113112148259111 0.33884415613920255\n",
       "  0.34673685045253166 0.35481338923357547 0.36307805477010141\n",
       "  0.37153522909717257 0.38018939632056115 0.38904514499428056\n",
       "  0.3981071705534972 0.40738027780411273 0.41686938347033542\n",
       "  0.42657951880159267 0.43651583224016599 0.44668359215096315\n",
       "  0.45708818961487507 0.46773514128719823 0.47863009232263842\n",
       "  0.48977881936844625 0.50118723362727235 0.51286138399136483\n",
       "  0.52480746024977254 0.53703179637025267 0.54954087385762451\n",
       "  0.56234132519034907 0.57543993733715693 0.58884365535558902\n",
       "  0.60255958607435778 0.61659500186148219 0.63095734448019336\n",
       "  0.64565422903465564 0.66069344800759611 0.67608297539198192\n",
       "  0.69183097091893642 0.70794578438413791 0.72443596007499\n",
       "  0.74131024130091749 0.75857757502918377 0.77624711662869172\n",
       "  0.79432823472428149 0.81283051616409929 0.83176377110267108\n",
       "  0.85113803820237655 0.87096358995608081 0.89125093813374567\n",
       "  0.91201083935590965 0.93325430079699101 0.95499258602143589\n",
       "  0.97723722095581067 1.0 1.0232929922807541 1.0471285480508996\n",
       "  1.0715193052376064 1.0964781961431851 1.1220184543019636\n",
       "  1.1481536214968828 1.1748975549395297 1.2022644346174132\n",
       "  1.2302687708123818 1.2589254117941675 1.2882495516931343\n",
       "  1.3182567385564075 1.348962882591654 1.3803842646028852 1.4125375446227548\n",
       "  1.4454397707459272 1.4791083881682072 1.513561248436208 1.5488166189124812\n",
       "  1.5848931924611134 1.6218100973589298 1.6595869074375604\n",
       "  1.6982436524617444 1.7378008287493754 1.7782794100389228\n",
       "  1.8197008586099834 1.8620871366628675 1.9054607179632472\n",
       "  1.9498445997580456 1.9952623149688797 2.0417379446695296\n",
       "  2.0892961308540396 2.1379620895022327 2.187761623949553 2.2387211385683399\n",
       "  2.2908676527677736 2.3442288153199229 2.3988329190194912 2.454708915685031\n",
       "  2.511886431509581 2.5703957827688635 2.6302679918953813 2.6915348039269151\n",
       "  2.7542287033381663 2.8183829312644537 2.8840315031266055\n",
       "  2.9512092266663856 3.0199517204020161 3.0902954325135905\n",
       "  3.1622776601683795 3.2359365692962827 3.3113112148259112\n",
       "  3.3884415613920256 3.4673685045253166 3.548133892335755 3.630780547701014\n",
       "  3.715352290971726 3.8018939632056128 3.8904514499428067 3.9810717055349731\n",
       "  4.0738027780411281 4.1686938347033546 4.2657951880159279 4.365158322401661\n",
       "  4.4668359215096327 4.5708818961487516 4.6773514128719809\n",
       "  4.7863009232263831 4.8977881936844616 5.011872336272722 5.1286138399136485\n",
       "  5.2480746024977254 5.3703179637025267 5.4954087385762458\n",
       "  5.6234132519034912 5.7543993733715695 5.8884365535558896\n",
       "  6.0255958607435778 6.1659500186148222 6.3095734448019334\n",
       "  6.4565422903465564 6.6069344800759611 6.7608297539198192\n",
       "  6.9183097091893657 7.0794578438413804 7.2443596007499025\n",
       "  7.4131024130091774 7.5857757502918401 7.7624711662869199\n",
       "  7.9432823472428176 8.1283051616409949 8.317637711026709 8.5113803820237628\n",
       "  8.709635899560805 8.9125093813374541 9.1201083935590965 9.3325430079699103\n",
       "  9.5499258602143584 9.7723722095581067 10.0],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'logisticregression__C': 0.10000000000000001},\n",
       "  {'logisticregression__C': 0.10232929922807542},\n",
       "  {'logisticregression__C': 0.10471285480508996},\n",
       "  {'logisticregression__C': 0.10715193052376065},\n",
       "  {'logisticregression__C': 0.10964781961431851},\n",
       "  {'logisticregression__C': 0.11220184543019636},\n",
       "  {'logisticregression__C': 0.11481536214968829},\n",
       "  {'logisticregression__C': 0.11748975549395298},\n",
       "  {'logisticregression__C': 0.12022644346174127},\n",
       "  {'logisticregression__C': 0.12302687708123815},\n",
       "  {'logisticregression__C': 0.12589254117941673},\n",
       "  {'logisticregression__C': 0.12882495516931339},\n",
       "  {'logisticregression__C': 0.1318256738556407},\n",
       "  {'logisticregression__C': 0.13489628825916536},\n",
       "  {'logisticregression__C': 0.13803842646028849},\n",
       "  {'logisticregression__C': 0.14125375446227545},\n",
       "  {'logisticregression__C': 0.14454397707459277},\n",
       "  {'logisticregression__C': 0.14791083881682077},\n",
       "  {'logisticregression__C': 0.15135612484362079},\n",
       "  {'logisticregression__C': 0.15488166189124811},\n",
       "  {'logisticregression__C': 0.15848931924611134},\n",
       "  {'logisticregression__C': 0.16218100973589297},\n",
       "  {'logisticregression__C': 0.16595869074375605},\n",
       "  {'logisticregression__C': 0.16982436524617442},\n",
       "  {'logisticregression__C': 0.17378008287493754},\n",
       "  {'logisticregression__C': 0.17782794100389229},\n",
       "  {'logisticregression__C': 0.18197008586099836},\n",
       "  {'logisticregression__C': 0.18620871366628675},\n",
       "  {'logisticregression__C': 0.19054607179632474},\n",
       "  {'logisticregression__C': 0.19498445997580455},\n",
       "  {'logisticregression__C': 0.19952623149688797},\n",
       "  {'logisticregression__C': 0.20417379446695297},\n",
       "  {'logisticregression__C': 0.20892961308540398},\n",
       "  {'logisticregression__C': 0.21379620895022325},\n",
       "  {'logisticregression__C': 0.21877616239495529},\n",
       "  {'logisticregression__C': 0.223872113856834},\n",
       "  {'logisticregression__C': 0.22908676527677729},\n",
       "  {'logisticregression__C': 0.2344228815319922},\n",
       "  {'logisticregression__C': 0.23988329190194904},\n",
       "  {'logisticregression__C': 0.24547089156850305},\n",
       "  {'logisticregression__C': 0.25118864315095801},\n",
       "  {'logisticregression__C': 0.25703957827688639},\n",
       "  {'logisticregression__C': 0.26302679918953814},\n",
       "  {'logisticregression__C': 0.26915348039269155},\n",
       "  {'logisticregression__C': 0.27542287033381663},\n",
       "  {'logisticregression__C': 0.28183829312644537},\n",
       "  {'logisticregression__C': 0.28840315031266056},\n",
       "  {'logisticregression__C': 0.29512092266663853},\n",
       "  {'logisticregression__C': 0.3019951720402016},\n",
       "  {'logisticregression__C': 0.30902954325135906},\n",
       "  {'logisticregression__C': 0.31622776601683794},\n",
       "  {'logisticregression__C': 0.32359365692962827},\n",
       "  {'logisticregression__C': 0.33113112148259111},\n",
       "  {'logisticregression__C': 0.33884415613920255},\n",
       "  {'logisticregression__C': 0.34673685045253166},\n",
       "  {'logisticregression__C': 0.35481338923357547},\n",
       "  {'logisticregression__C': 0.36307805477010141},\n",
       "  {'logisticregression__C': 0.37153522909717257},\n",
       "  {'logisticregression__C': 0.38018939632056115},\n",
       "  {'logisticregression__C': 0.38904514499428056},\n",
       "  {'logisticregression__C': 0.3981071705534972},\n",
       "  {'logisticregression__C': 0.40738027780411273},\n",
       "  {'logisticregression__C': 0.41686938347033542},\n",
       "  {'logisticregression__C': 0.42657951880159267},\n",
       "  {'logisticregression__C': 0.43651583224016599},\n",
       "  {'logisticregression__C': 0.44668359215096315},\n",
       "  {'logisticregression__C': 0.45708818961487507},\n",
       "  {'logisticregression__C': 0.46773514128719823},\n",
       "  {'logisticregression__C': 0.47863009232263842},\n",
       "  {'logisticregression__C': 0.48977881936844625},\n",
       "  {'logisticregression__C': 0.50118723362727235},\n",
       "  {'logisticregression__C': 0.51286138399136483},\n",
       "  {'logisticregression__C': 0.52480746024977254},\n",
       "  {'logisticregression__C': 0.53703179637025267},\n",
       "  {'logisticregression__C': 0.54954087385762451},\n",
       "  {'logisticregression__C': 0.56234132519034907},\n",
       "  {'logisticregression__C': 0.57543993733715693},\n",
       "  {'logisticregression__C': 0.58884365535558902},\n",
       "  {'logisticregression__C': 0.60255958607435778},\n",
       "  {'logisticregression__C': 0.61659500186148219},\n",
       "  {'logisticregression__C': 0.63095734448019336},\n",
       "  {'logisticregression__C': 0.64565422903465564},\n",
       "  {'logisticregression__C': 0.66069344800759611},\n",
       "  {'logisticregression__C': 0.67608297539198192},\n",
       "  {'logisticregression__C': 0.69183097091893642},\n",
       "  {'logisticregression__C': 0.70794578438413791},\n",
       "  {'logisticregression__C': 0.72443596007499},\n",
       "  {'logisticregression__C': 0.74131024130091749},\n",
       "  {'logisticregression__C': 0.75857757502918377},\n",
       "  {'logisticregression__C': 0.77624711662869172},\n",
       "  {'logisticregression__C': 0.79432823472428149},\n",
       "  {'logisticregression__C': 0.81283051616409929},\n",
       "  {'logisticregression__C': 0.83176377110267108},\n",
       "  {'logisticregression__C': 0.85113803820237655},\n",
       "  {'logisticregression__C': 0.87096358995608081},\n",
       "  {'logisticregression__C': 0.89125093813374567},\n",
       "  {'logisticregression__C': 0.91201083935590965},\n",
       "  {'logisticregression__C': 0.93325430079699101},\n",
       "  {'logisticregression__C': 0.95499258602143589},\n",
       "  {'logisticregression__C': 0.97723722095581067},\n",
       "  {'logisticregression__C': 1.0},\n",
       "  {'logisticregression__C': 1.0232929922807541},\n",
       "  {'logisticregression__C': 1.0471285480508996},\n",
       "  {'logisticregression__C': 1.0715193052376064},\n",
       "  {'logisticregression__C': 1.0964781961431851},\n",
       "  {'logisticregression__C': 1.1220184543019636},\n",
       "  {'logisticregression__C': 1.1481536214968828},\n",
       "  {'logisticregression__C': 1.1748975549395297},\n",
       "  {'logisticregression__C': 1.2022644346174132},\n",
       "  {'logisticregression__C': 1.2302687708123818},\n",
       "  {'logisticregression__C': 1.2589254117941675},\n",
       "  {'logisticregression__C': 1.2882495516931343},\n",
       "  {'logisticregression__C': 1.3182567385564075},\n",
       "  {'logisticregression__C': 1.348962882591654},\n",
       "  {'logisticregression__C': 1.3803842646028852},\n",
       "  {'logisticregression__C': 1.4125375446227548},\n",
       "  {'logisticregression__C': 1.4454397707459272},\n",
       "  {'logisticregression__C': 1.4791083881682072},\n",
       "  {'logisticregression__C': 1.513561248436208},\n",
       "  {'logisticregression__C': 1.5488166189124812},\n",
       "  {'logisticregression__C': 1.5848931924611134},\n",
       "  {'logisticregression__C': 1.6218100973589298},\n",
       "  {'logisticregression__C': 1.6595869074375604},\n",
       "  {'logisticregression__C': 1.6982436524617444},\n",
       "  {'logisticregression__C': 1.7378008287493754},\n",
       "  {'logisticregression__C': 1.7782794100389228},\n",
       "  {'logisticregression__C': 1.8197008586099834},\n",
       "  {'logisticregression__C': 1.8620871366628675},\n",
       "  {'logisticregression__C': 1.9054607179632472},\n",
       "  {'logisticregression__C': 1.9498445997580456},\n",
       "  {'logisticregression__C': 1.9952623149688797},\n",
       "  {'logisticregression__C': 2.0417379446695296},\n",
       "  {'logisticregression__C': 2.0892961308540396},\n",
       "  {'logisticregression__C': 2.1379620895022327},\n",
       "  {'logisticregression__C': 2.187761623949553},\n",
       "  {'logisticregression__C': 2.2387211385683399},\n",
       "  {'logisticregression__C': 2.2908676527677736},\n",
       "  {'logisticregression__C': 2.3442288153199229},\n",
       "  {'logisticregression__C': 2.3988329190194912},\n",
       "  {'logisticregression__C': 2.454708915685031},\n",
       "  {'logisticregression__C': 2.511886431509581},\n",
       "  {'logisticregression__C': 2.5703957827688635},\n",
       "  {'logisticregression__C': 2.6302679918953813},\n",
       "  {'logisticregression__C': 2.6915348039269151},\n",
       "  {'logisticregression__C': 2.7542287033381663},\n",
       "  {'logisticregression__C': 2.8183829312644537},\n",
       "  {'logisticregression__C': 2.8840315031266055},\n",
       "  {'logisticregression__C': 2.9512092266663856},\n",
       "  {'logisticregression__C': 3.0199517204020161},\n",
       "  {'logisticregression__C': 3.0902954325135905},\n",
       "  {'logisticregression__C': 3.1622776601683795},\n",
       "  {'logisticregression__C': 3.2359365692962827},\n",
       "  {'logisticregression__C': 3.3113112148259112},\n",
       "  {'logisticregression__C': 3.3884415613920256},\n",
       "  {'logisticregression__C': 3.4673685045253166},\n",
       "  {'logisticregression__C': 3.548133892335755},\n",
       "  {'logisticregression__C': 3.630780547701014},\n",
       "  {'logisticregression__C': 3.715352290971726},\n",
       "  {'logisticregression__C': 3.8018939632056128},\n",
       "  {'logisticregression__C': 3.8904514499428067},\n",
       "  {'logisticregression__C': 3.9810717055349731},\n",
       "  {'logisticregression__C': 4.0738027780411281},\n",
       "  {'logisticregression__C': 4.1686938347033546},\n",
       "  {'logisticregression__C': 4.2657951880159279},\n",
       "  {'logisticregression__C': 4.365158322401661},\n",
       "  {'logisticregression__C': 4.4668359215096327},\n",
       "  {'logisticregression__C': 4.5708818961487516},\n",
       "  {'logisticregression__C': 4.6773514128719809},\n",
       "  {'logisticregression__C': 4.7863009232263831},\n",
       "  {'logisticregression__C': 4.8977881936844616},\n",
       "  {'logisticregression__C': 5.011872336272722},\n",
       "  {'logisticregression__C': 5.1286138399136485},\n",
       "  {'logisticregression__C': 5.2480746024977254},\n",
       "  {'logisticregression__C': 5.3703179637025267},\n",
       "  {'logisticregression__C': 5.4954087385762458},\n",
       "  {'logisticregression__C': 5.6234132519034912},\n",
       "  {'logisticregression__C': 5.7543993733715695},\n",
       "  {'logisticregression__C': 5.8884365535558896},\n",
       "  {'logisticregression__C': 6.0255958607435778},\n",
       "  {'logisticregression__C': 6.1659500186148222},\n",
       "  {'logisticregression__C': 6.3095734448019334},\n",
       "  {'logisticregression__C': 6.4565422903465564},\n",
       "  {'logisticregression__C': 6.6069344800759611},\n",
       "  {'logisticregression__C': 6.7608297539198192},\n",
       "  {'logisticregression__C': 6.9183097091893657},\n",
       "  {'logisticregression__C': 7.0794578438413804},\n",
       "  {'logisticregression__C': 7.2443596007499025},\n",
       "  {'logisticregression__C': 7.4131024130091774},\n",
       "  {'logisticregression__C': 7.5857757502918401},\n",
       "  {'logisticregression__C': 7.7624711662869199},\n",
       "  {'logisticregression__C': 7.9432823472428176},\n",
       "  {'logisticregression__C': 8.1283051616409949},\n",
       "  {'logisticregression__C': 8.317637711026709},\n",
       "  {'logisticregression__C': 8.5113803820237628},\n",
       "  {'logisticregression__C': 8.709635899560805},\n",
       "  {'logisticregression__C': 8.9125093813374541},\n",
       "  {'logisticregression__C': 9.1201083935590965},\n",
       "  {'logisticregression__C': 9.3325430079699103},\n",
       "  {'logisticregression__C': 9.5499258602143584},\n",
       "  {'logisticregression__C': 9.7723722095581067},\n",
       "  {'logisticregression__C': 10.0}),\n",
       " 'rank_test_score': array([  1,   1,   1,   4,   4,   4,   4,   4,   4,   4,  11,  11,  11,\n",
       "         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,\n",
       "         11,  11,  11,  11,  11,  11,  11,  34,  34,  34,  34,  65,  65,\n",
       "         65,  65,  65,  65,  85,  85, 113, 113, 113, 113, 113, 113, 113,\n",
       "        160, 160, 160, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185,\n",
       "        160, 160, 160, 160, 160, 160, 120, 120, 120, 120, 120, 140, 140,\n",
       "        140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140,\n",
       "        140, 140, 140, 140, 140, 171, 171, 171, 171, 171, 132, 132, 132,\n",
       "        132, 132, 132, 132, 132, 171, 171, 171, 171, 171, 171, 171, 171,\n",
       "        171, 198, 198, 198, 198, 160, 160, 195, 195, 195, 125, 125, 125,\n",
       "        125, 125, 125, 125,  87,  87,  87,  87,  87,  87,  87,  87,  71,\n",
       "         71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  38,  38,\n",
       "         38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
       "         38,  38,  38,  38,  38,  38,  95,  95,  95,  95,  95,  95,  95,\n",
       "         95,  95,  95,  95,  95,  95,  95,  95,  95,  95,  95,  83,  83,\n",
       "         59,  59,  59,  59,  59,  59]),\n",
       " 'split0_test_score': array([ 0.72727273,  0.72727273,  0.72727273,  0.72727273,  0.72727273,\n",
       "         0.72727273,  0.72727273,  0.72727273,  0.72727273,  0.72727273,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545]),\n",
       " 'split0_train_score': array([ 0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.85714286,  0.85714286,  0.85714286,\n",
       "         0.85714286,  0.85714286,  0.85714286,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.85714286,  0.85714286,  0.85714286,  0.85714286,  0.85714286,\n",
       "         0.85714286,  0.85714286,  0.85714286,  0.85714286,  0.85714286,\n",
       "         0.85714286,  0.85714286,  0.85714286,  0.85714286,  0.85714286,\n",
       "         0.85714286,  0.85714286,  0.85714286,  0.85714286,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.95238095,  0.95238095,  0.95238095,  0.95238095,\n",
       "         0.95238095,  0.95238095,  0.95238095,  0.95238095,  0.95238095,\n",
       "         0.95238095,  0.95238095,  0.95238095,  0.95238095,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split1_test_score': array([ 0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.63636364,  0.63636364,  0.63636364,  0.63636364,  0.63636364,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.45454545,  0.45454545,  0.45454545,\n",
       "         0.45454545,  0.45454545,  0.54545455,  0.54545455,  0.54545455,\n",
       "         0.54545455,  0.54545455,  0.72727273,  0.72727273,  0.72727273,\n",
       "         0.72727273,  0.72727273,  0.72727273,  0.72727273,  0.72727273,\n",
       "         0.72727273,  0.72727273,  0.72727273,  0.72727273,  0.72727273,\n",
       "         0.72727273,  0.72727273,  0.72727273,  0.72727273,  0.72727273,\n",
       "         0.72727273,  0.72727273,  0.72727273,  0.72727273,  0.72727273,\n",
       "         0.72727273,  0.72727273,  0.72727273,  0.72727273,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.81818182,  0.90909091,  0.90909091,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split1_train_score': array([ 0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.85714286,\n",
       "         0.85714286,  0.85714286,  0.85714286,  0.85714286,  0.85714286,\n",
       "         0.85714286,  0.85714286,  0.85714286,  0.80952381,  0.80952381,\n",
       "         0.80952381,  0.80952381,  0.80952381,  0.80952381,  0.80952381,\n",
       "         0.80952381,  0.80952381,  0.80952381,  0.80952381,  0.80952381,\n",
       "         0.80952381,  0.80952381,  0.85714286,  0.85714286,  0.85714286,\n",
       "         0.85714286,  0.85714286,  0.85714286,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,  0.9047619 ,\n",
       "         0.9047619 ,  0.9047619 ,  0.95238095,  0.95238095,  0.95238095,\n",
       "         0.95238095,  0.95238095,  0.95238095,  0.95238095,  0.95238095,\n",
       "         0.95238095,  0.95238095,  0.95238095,  0.95238095,  0.95238095,\n",
       "         0.95238095,  0.95238095,  0.95238095,  0.95238095,  0.95238095,\n",
       "         0.95238095,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split2_test_score': array([ 0.9,  0.9,  0.9,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,\n",
       "         0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,\n",
       "         0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,  0.8,\n",
       "         0.7,  0.7,  0.7,  0.7,  0.7,  0.7,  0.7,  0.7,  0.7,  0.7,  0.6,\n",
       "         0.6,  0.6,  0.6,  0.6,  0.6,  0.6,  0.6,  0.6,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.6,  0.6,  0.6,  0.6,  0.6,  0.6,  0.6,  0.6,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.4,  0.4,  0.4,  0.4,  0.4,  0.4,  0.4,  0.4,\n",
       "         0.4,  0.4,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,  0.5,\n",
       "         0.5,  0.5,  0.5]),\n",
       " 'split2_train_score': array([ 0.86363636,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
       "         0.81818182,  0.77272727,  0.77272727,  0.72727273,  0.81818182,\n",
       "         0.81818182,  0.81818182,  0.86363636,  0.86363636,  0.81818182,\n",
       "         0.86363636,  0.86363636,  0.86363636,  0.86363636,  0.81818182,\n",
       "         0.81818182,  0.77272727,  0.77272727,  0.77272727,  0.77272727,\n",
       "         0.77272727,  0.77272727,  0.77272727,  0.77272727,  0.77272727,\n",
       "         0.86363636,  0.86363636,  0.86363636,  0.86363636,  0.86363636,\n",
       "         0.86363636,  0.86363636,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.86363636,\n",
       "         0.86363636,  0.86363636,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.86363636,  0.86363636,\n",
       "         0.86363636,  0.86363636,  0.86363636,  0.86363636,  0.86363636,\n",
       "         0.86363636,  0.86363636,  0.86363636,  0.86363636,  0.86363636,\n",
       "         0.86363636,  0.86363636,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.90909091,  0.90909091,  0.90909091,\n",
       "         0.90909091,  0.90909091,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545,  0.95454545,  0.95454545,  0.95454545,  0.95454545,\n",
       "         0.95454545]),\n",
       " 'std_fit_time': array([  4.71370716e-04,   4.67938695e-04,   9.44539956e-04,\n",
       "          8.25203897e-04,   4.73393402e-04,   4.74338715e-04,\n",
       "          9.61391695e-06,   8.88746806e-06,   8.82327717e-06,\n",
       "          4.71988518e-04,   1.94667955e-07,   4.67420677e-04,\n",
       "          4.69347466e-04,   1.41529134e-03,   9.79807218e-07,\n",
       "          4.71764216e-04,   4.72326896e-04,   9.43808473e-04,\n",
       "          4.81317020e-04,   1.12391596e-07,   9.16043220e-06,\n",
       "          5.61957980e-07,   9.44891863e-06,   8.59850802e-06,\n",
       "          4.89903609e-07,   1.12391596e-07,   4.05233662e-07,\n",
       "          9.38520301e-06,   7.01885292e-07,   1.12391596e-07,\n",
       "          4.05233662e-07,   4.05233662e-07,   1.12391596e-07,\n",
       "          2.97360213e-07,   1.12391596e-07,   1.94667955e-07,\n",
       "          1.69707588e-06,   1.12391596e-07,   6.74349576e-07,\n",
       "          1.12391596e-07,   2.24783192e-07,   7.86741172e-07,\n",
       "          1.12391596e-07,   4.05233662e-07,   1.94667955e-07,\n",
       "          2.97360213e-07,   0.00000000e+00,   5.15042996e-07,\n",
       "          2.24783192e-07,   1.03008599e-06,   4.71932352e-04,\n",
       "          4.49566384e-07,   1.94667955e-07,   4.71932472e-04,\n",
       "          4.89903609e-07,   4.05233662e-07,   4.67256027e-04,\n",
       "          4.71707529e-04,   4.67028628e-04,   2.97360213e-07,\n",
       "          4.89903609e-07,   1.12391596e-07,   1.12391596e-07,\n",
       "          5.15042996e-07,   1.12391596e-07,   4.71595137e-04,\n",
       "          8.54397927e-06,   4.75932946e-04,   2.24783192e-07,\n",
       "          5.61957980e-07,   3.37174788e-07,   8.65415289e-06,\n",
       "          4.71819920e-04,   4.71426560e-04,   6.25769923e-07,\n",
       "          3.37174788e-07,   4.71988518e-04,   4.71651343e-04,\n",
       "          1.94667955e-07,   6.25769923e-07,   4.67875469e-04,\n",
       "          3.89335909e-07,   1.12391596e-07,   3.89335909e-07,\n",
       "          4.71482745e-04,   2.24783192e-07,   4.71314248e-04,\n",
       "          2.97360213e-07,   3.37174788e-07,   4.71539192e-04,\n",
       "          4.71651343e-04,   4.05233662e-07,   5.61957980e-07,\n",
       "          4.71651423e-04,   4.70415035e-04,   4.71876206e-04,\n",
       "          4.71145933e-04,   4.72269647e-04,   2.24783192e-07,\n",
       "          4.71370394e-04,   4.71763975e-04,   4.71820081e-04,\n",
       "          4.62997190e-04,   4.71538951e-04,   1.94667955e-07,\n",
       "          1.94667955e-07,   4.71145731e-04,   4.71145571e-04,\n",
       "          4.71426640e-04,   4.71932352e-04,   4.71145571e-04,\n",
       "          4.71201857e-04,   4.71370354e-04,   4.71482786e-04,\n",
       "          1.24759607e-03,   4.71935564e-04,   4.71595177e-04,\n",
       "          4.71482745e-04,   4.70864843e-04,   4.70920787e-04,\n",
       "          4.72494310e-04,   4.71482786e-04,   4.72326495e-04,\n",
       "          4.71089385e-04,   4.71707569e-04,   4.71370515e-04,\n",
       "          4.71145611e-04,   4.71746343e-04,   2.97360213e-07,\n",
       "          1.12391596e-07,   4.71820081e-04,   4.71819920e-04,\n",
       "          4.62435232e-04,   6.74349576e-07,   8.66290625e-06,\n",
       "          0.00000000e+00,   4.79857114e-04,   4.81036189e-04,\n",
       "          4.70977074e-04,   9.33053342e-06,   8.16196801e-04,\n",
       "          1.12391596e-07,   1.53890323e-05,   4.71763815e-04,\n",
       "          4.71443226e-04,   1.43663544e-05,   4.72438084e-04,\n",
       "          4.75753440e-04,   4.62210695e-04,   4.76367136e-04,\n",
       "          4.70864843e-04,   4.61592449e-04,   4.66949724e-04,\n",
       "          9.29915928e-04,   4.76810309e-04,   4.71426801e-04,\n",
       "          9.41729264e-04,   4.71595137e-04,   4.73629747e-04,\n",
       "          8.16534784e-04,   8.16826807e-04,   9.43302665e-04,\n",
       "          9.43358866e-04,   9.52350433e-04,   4.71482745e-04,\n",
       "          9.43471258e-04,   9.47605539e-04,   8.17021529e-04,\n",
       "          1.24823358e-03,   8.16437433e-04,   1.12391596e-07,\n",
       "          6.25769923e-07,   8.17216197e-04,   2.97360213e-07,\n",
       "          4.75811133e-04,   2.97360213e-07,   4.79968321e-04,\n",
       "          4.71539032e-04,   1.12391596e-07,   2.97360213e-07,\n",
       "          4.76951003e-04,   4.49566384e-07,   9.43134204e-04,\n",
       "          9.43752553e-04,   8.17118788e-04,   9.38947020e-04,\n",
       "          9.52125650e-04,   8.15951291e-04,   8.17021406e-04,\n",
       "          9.39569012e-04,   1.68991404e-03,   1.63306948e-03,\n",
       "          1.24567270e-03,   9.43471258e-04,   9.42909340e-04,\n",
       "          1.41495400e-03,   8.16437471e-04,   8.16729421e-04,\n",
       "          8.22474597e-04,   9.43639840e-04,   9.43639840e-04]),\n",
       " 'std_score_time': array([  2.24783192e-07,   1.03613836e-05,   4.72044864e-04,\n",
       "          8.08762795e-04,   1.36267568e-06,   4.72494270e-04,\n",
       "          4.71707689e-04,   1.12391596e-07,   4.76324640e-04,\n",
       "          5.94720425e-07,   4.71482745e-04,   8.16730102e-04,\n",
       "          8.26290012e-04,   5.15042996e-07,   4.49566384e-07,\n",
       "          4.75644461e-04,   4.71426560e-04,   2.24783192e-07,\n",
       "          2.97360213e-07,   4.71595177e-04,   4.71876367e-04,\n",
       "          4.71482906e-04,   4.71370354e-04,   4.71819960e-04,\n",
       "          2.24783192e-07,   6.83651389e-07,   4.71539032e-04,\n",
       "          9.60997439e-06,   4.71707529e-04,   2.97360213e-07,\n",
       "          4.71988598e-04,   2.24783192e-07,   3.37174788e-07,\n",
       "          4.71932312e-04,   0.00000000e+00,   4.49566384e-07,\n",
       "          7.37000982e-07,   4.71707529e-04,   2.24783192e-07,\n",
       "          1.12391596e-07,   4.71763734e-04,   2.97360213e-07,\n",
       "          4.71707529e-04,   4.71988518e-04,   1.94667955e-07,\n",
       "          3.89335909e-07,   4.89903609e-07,   2.97360213e-07,\n",
       "          1.12391596e-07,   4.49566384e-07,   4.71819960e-04,\n",
       "          5.15042996e-07,   8.92080638e-07,   4.71707529e-04,\n",
       "          7.78671819e-07,   1.94667955e-07,   4.71707529e-04,\n",
       "          1.94667955e-07,   4.71763734e-04,   3.37174788e-07,\n",
       "          1.12391596e-07,   2.97360213e-07,   6.25769923e-07,\n",
       "          4.71819920e-04,   4.72383322e-04,   0.00000000e+00,\n",
       "          4.71595177e-04,   4.70869028e-04,   2.24783192e-07,\n",
       "          5.15042996e-07,   1.94667955e-07,   3.37174788e-07,\n",
       "          0.00000000e+00,   4.71482745e-04,   4.71482906e-04,\n",
       "          5.15042996e-07,   4.71763815e-04,   0.00000000e+00,\n",
       "          4.71595137e-04,   8.38730522e-06,   4.66997441e-04,\n",
       "          6.83651389e-07,   0.00000000e+00,   2.24783192e-07,\n",
       "          1.56139395e-06,   2.24783192e-07,   4.71482745e-04,\n",
       "          1.12391596e-07,   4.89903609e-07,   5.15042996e-07,\n",
       "          4.71595177e-04,   3.37174788e-07,   1.12391596e-07,\n",
       "          1.94667955e-07,   4.71595177e-04,   4.71651423e-04,\n",
       "          8.93566202e-06,   4.72045065e-04,   1.01152436e-06,\n",
       "          4.71539032e-04,   4.71539192e-04,   3.89335909e-07,\n",
       "          4.71595137e-04,   0.00000000e+00,   1.12391596e-07,\n",
       "          4.71707529e-04,   3.37174788e-07,   2.97360213e-07,\n",
       "          2.24783192e-07,   2.24783192e-07,   4.71482745e-04,\n",
       "          4.71707529e-04,   4.71482745e-04,   2.97360213e-07,\n",
       "          4.71932472e-04,   6.83651389e-07,   1.94667955e-07,\n",
       "          4.71595177e-04,   4.71482786e-04,   4.71595177e-04,\n",
       "          2.24783192e-07,   4.71370354e-04,   4.72045065e-04,\n",
       "          4.71370354e-04,   8.77806426e-07,   4.71707529e-04,\n",
       "          4.71482906e-04,   5.61957980e-07,   4.71707529e-04,\n",
       "          4.71651343e-04,   7.08334603e-06,   4.71595177e-04,\n",
       "          6.83651389e-07,   4.66949724e-04,   8.48537942e-07,\n",
       "          4.66803865e-04,   4.89903609e-07,   0.00000000e+00,\n",
       "          1.21570099e-06,   4.63446756e-04,   4.71595177e-04,\n",
       "          9.98958356e-07,   1.94667955e-07,   0.00000000e+00,\n",
       "          1.43399521e-05,   6.80038817e-06,   4.71651825e-04,\n",
       "          8.54397927e-06,   8.99343478e-06,   4.71482906e-04,\n",
       "          4.75695767e-04,   1.29616312e-06,   4.72157255e-04,\n",
       "          4.71989320e-04,   0.00000000e+00,   1.18411894e-06,\n",
       "          2.61416184e-06,   8.48537942e-07,   2.30608275e-06,\n",
       "          6.74349576e-07,   1.12391596e-07,   4.71819960e-04,\n",
       "          2.97360213e-07,   9.73339773e-07,   4.71707529e-04,\n",
       "          4.89903609e-07,   4.76093600e-04,   4.67662214e-04,\n",
       "          8.17216143e-04,   8.17410811e-04,   0.00000000e+00,\n",
       "          4.72044743e-04,   1.12391596e-07,   4.72269647e-04,\n",
       "          8.15362106e-06,   4.71707529e-04,   4.67495178e-04,\n",
       "          8.26594154e-06,   4.67443701e-04,   8.48537942e-07,\n",
       "          3.37174788e-07,   4.72325692e-04,   4.72100989e-04,\n",
       "          9.01027380e-06,   1.12391596e-07,   1.45115788e-05,\n",
       "          4.67552916e-04,   7.86741172e-07,   8.20689560e-06,\n",
       "          4.71595177e-04,   4.58351408e-04,   2.97360213e-07,\n",
       "          9.79807218e-07,   0.00000000e+00,   1.12391596e-07,\n",
       "          5.94720425e-07,   4.05233662e-07,   1.12391596e-07,\n",
       "          6.57562879e-06,   5.15042996e-07,   4.71595177e-04]),\n",
       " 'std_test_score': array([ 0.1083515 ,  0.1083515 ,  0.1083515 ,  0.06645542,  0.06645542,\n",
       "         0.06645542,  0.06645542,  0.06645542,  0.06645542,  0.06645542,\n",
       "         0.07651492,  0.07651492,  0.07651492,  0.07651492,  0.07651492,\n",
       "         0.07651492,  0.07651492,  0.07651492,  0.07651492,  0.07651492,\n",
       "         0.07651492,  0.07651492,  0.07651492,  0.07651492,  0.07651492,\n",
       "         0.07651492,  0.07651492,  0.07651492,  0.07651492,  0.07651492,\n",
       "         0.07651492,  0.07651492,  0.07651492,  0.0297558 ,  0.0297558 ,\n",
       "         0.0297558 ,  0.0297558 ,  0.06351442,  0.06351442,  0.06351442,\n",
       "         0.06351442,  0.06351442,  0.06351442,  0.03767702,  0.03767702,\n",
       "         0.02550497,  0.02550497,  0.02550497,  0.02550497,  0.02550497,\n",
       "         0.02550497,  0.02550497,  0.02125414,  0.02125414,  0.02125414,\n",
       "         0.03739931,  0.03739931,  0.03739931,  0.03739931,  0.03739931,\n",
       "         0.03739931,  0.03739931,  0.03739931,  0.03739931,  0.03739931,\n",
       "         0.02125414,  0.02125414,  0.02125414,  0.02125414,  0.02125414,\n",
       "         0.02125414,  0.05686354,  0.05686354,  0.05686354,  0.05686354,\n",
       "         0.05686354,  0.07793825,  0.07793825,  0.07793825,  0.07793825,\n",
       "         0.07793825,  0.07793825,  0.07793825,  0.07793825,  0.07793825,\n",
       "         0.07793825,  0.07793825,  0.07793825,  0.07793825,  0.07793825,\n",
       "         0.07793825,  0.07793825,  0.07793825,  0.07793825,  0.07793825,\n",
       "         0.07793825,  0.03739931,  0.03739931,  0.03739931,  0.03739931,\n",
       "         0.03739931,  0.05962   ,  0.05962   ,  0.05962   ,  0.05962   ,\n",
       "         0.05962   ,  0.05962   ,  0.05962   ,  0.05962   ,  0.03739931,\n",
       "         0.03739931,  0.03739931,  0.03739931,  0.03739931,  0.03739931,\n",
       "         0.03739931,  0.03739931,  0.03739931,  0.02125414,  0.02125414,\n",
       "         0.02125414,  0.02125414,  0.02125414,  0.02125414,  0.06801326,\n",
       "         0.06801326,  0.06801326,  0.13291083,  0.13291083,  0.13291083,\n",
       "         0.13291083,  0.13291083,  0.13291083,  0.13291083,  0.09786257,\n",
       "         0.09786257,  0.09786257,  0.09786257,  0.09786257,  0.09786257,\n",
       "         0.09786257,  0.09786257,  0.0925793 ,  0.0925793 ,  0.0925793 ,\n",
       "         0.0925793 ,  0.0925793 ,  0.0925793 ,  0.0925793 ,  0.0925793 ,\n",
       "         0.0925793 ,  0.0925793 ,  0.0925793 ,  0.0925793 ,  0.1294191 ,\n",
       "         0.1294191 ,  0.1294191 ,  0.1294191 ,  0.1294191 ,  0.1294191 ,\n",
       "         0.1294191 ,  0.1294191 ,  0.1294191 ,  0.1294191 ,  0.1294191 ,\n",
       "         0.1294191 ,  0.1294191 ,  0.1294191 ,  0.1294191 ,  0.1294191 ,\n",
       "         0.1294191 ,  0.1294191 ,  0.1294191 ,  0.1294191 ,  0.1294191 ,\n",
       "         0.16210547,  0.16210547,  0.16210547,  0.16210547,  0.16210547,\n",
       "         0.16210547,  0.16210547,  0.16210547,  0.16210547,  0.16210547,\n",
       "         0.16210547,  0.16210547,  0.16210547,  0.16210547,  0.16210547,\n",
       "         0.16210547,  0.16210547,  0.16210547,  0.20473772,  0.20473772,\n",
       "         0.24744691,  0.24744691,  0.24744691,  0.24744691,  0.24744691,\n",
       "         0.24744691]),\n",
       " 'std_train_score': array([ 0.01938677,  0.04081424,  0.04081424,  0.04081424,  0.04081424,\n",
       "         0.04081424,  0.06224172,  0.06224172,  0.0836692 ,  0.04081424,\n",
       "         0.04081424,  0.04081424,  0.01938677,  0.01938677,  0.03540503,\n",
       "         0.02108462,  0.02108462,  0.00306107,  0.00306107,  0.01836641,\n",
       "         0.01836641,  0.03979389,  0.03979389,  0.05563514,  0.05563514,\n",
       "         0.05563514,  0.05563514,  0.05563514,  0.05563514,  0.05563514,\n",
       "         0.0390011 ,  0.0390011 ,  0.0390011 ,  0.0390011 ,  0.0390011 ,\n",
       "         0.0390011 ,  0.0390011 ,  0.02353464,  0.02353464,  0.02353464,\n",
       "         0.02353464,  0.02353464,  0.02353464,  0.00204071,  0.00204071,\n",
       "         0.02353464,  0.02353464,  0.02353464,  0.02353464,  0.02353464,\n",
       "         0.02353464,  0.02353464,  0.02353464,  0.02353464,  0.02353464,\n",
       "         0.02353464,  0.02353464,  0.03893431,  0.03893431,  0.04344609,\n",
       "         0.04344609,  0.04344609,  0.03893431,  0.03893431,  0.02150024,\n",
       "         0.02150024,  0.02150024,  0.02150024,  0.02150024,  0.02150024,\n",
       "         0.02150024,  0.02040712,  0.02040712,  0.02040712,  0.02040712,\n",
       "         0.02040712,  0.0371275 ,  0.0371275 ,  0.0371275 ,  0.0371275 ,\n",
       "         0.0371275 ,  0.0371275 ,  0.0371275 ,  0.0371275 ,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.04285496,  0.06428243,  0.06428243,\n",
       "         0.06428243,  0.06428243,  0.06428243,  0.06428243,  0.06428243,\n",
       "         0.06428243,  0.06428243,  0.06428243,  0.06428243,  0.06428243,\n",
       "         0.06428243,  0.06428243,  0.04285496,  0.04285496,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.04285496,  0.04285496,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.04285496,  0.04285496,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.04285496,  0.04285496,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.04285496,  0.04285496,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.04285496,  0.04285496,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.04285496,  0.04285496,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.04285496,  0.04285496,  0.04285496,\n",
       "         0.04285496,  0.04285496,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748,  0.02142748,  0.02142748,  0.02142748,  0.02142748,\n",
       "         0.02142748])}"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_new.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
